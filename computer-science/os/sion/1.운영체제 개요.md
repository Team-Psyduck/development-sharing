## CPU 스케줄링

### FCFS (First-Come First-Served)

선착순으로 먼저 도착한 프로세스에게 먼저 CPU를 사용할 수 있게 해준다. 

- 생각보다 효율적이지 않은 스케줄링 방법이다.
- 프로세스 3개가 존재하고 모든 프로세스들이 기다린 시간의 평균을 내본다고 했을 때.
    
    p1 = 24, p2 = 3, p3 = 3 (각각의 프로세스들의 소요 작업 시간 
    
    - p1이 먼저 선점할 경우 p2는 24초를 기다려야하고, p3는 27초를 기다려야한다. 따라서 평균 대기시간이 17초가 된다.
    - 하지만 만약 p1이 마지막으로 작업할 경우 p3는 3초를 기다리되고, p1은 6초를 기다리게 됨으로 평균 대기시간이 3초가 된다.

### SJF (Shortest-Job-First)

금번 CPU 사용시간이 가장 짧은 프로세스를 제일 먼저 스케줄링한다. 

- SJF는 `minimum average wating time`을 보장해 준다.
- 평균대기 시간을 최고로 짧게 보장하고 싶다면 이 방법을 사용하면 된다. 하지만, 문제는 효율성이 좋지만 형평성의 문제점이 존재한다. (Starvation [기아현상] 발생 가능)
- CPU를 긴 시간동안 사용해야 하는 프로그램은 영원히 CPU를 사용하지 못할 수 있는 문제점이 존재한다.

💡 CPU가 자원을 관리할 떄는 효율성과 형평성을 모두 고려해야 한다.

💡 FCFS 방식과 SJF방식은 CPU의 사용 권한을 중간에 뺏지 않는다. (할당시간이라는 개념이 없음)

### RR (Round Robin)

각 프로세스는 동일 크기의 CPU 할당시간을 가지고 할당시간이 끝나면 인터럽트가 발생하여 프로세스는 CPU를 빼앗기고 CPU큐의 제일 뒤에 줄을 선다. 

- 현재 CPU 스케줄링에서 가장 많이 사용되는 아이디어이다.
- n개의 프로세스가 CPU 큐에 존재할 경우
    - 어떤 프로세스도 (n-1)*할당시간 이상 기다리지 않는다. (공정성)
    - 대기시간이 프로세스의 CPU 사용시간에 비례한다. (공정성)

## 메모리 관리
![스크린샷 2023-06-05 오후 5 41 56](https://github.com/SionBackEnd/tech-sharing/assets/104377048/b5d1a572-f599-4e8a-aa9d-2c7424c5aa37)



위 그림에서 디스크를 제외한 다른 영역은 모두 컴퓨터가 종료되면 불필요한 정보가 되어 버린다. (디스크 - 영구적인 저장매체)

디스크에서 실행파일을 실행하면 메모리에 프로세스가 실행되게 된다. 이때 메모리에 실행파일이 한번에 올라가는 것이 아니라 가상메모리라는 가상의 메모리 공간을 할당받는다. 가상메모리에 해당 프로세스가 해야할 작업을 올려두고 실질적으로 당장 실행할 작업을 메모리 영역에 올려서 실질적인 작업을 진행한다. 

디스크(스왑영역)은 메모리영역의 공간이 꽉 차게 되었을때 메모리 영역에 존재하는 페이지 중 하나를 스왑영역에 옮기게 된다. 즉, 스왑영역 메모리의 연장선이다. (메모리에 개인 Repository)

스왑영역은 비휘발성은 아니지만, 컴퓨터가 종료되면 함께 종료된 프로세스의 정보는 필요가 없기 때문에 지워버려야하는 불필요한 정보만을 저장하고 있는 상태가 된다. 

## CPU - Memory - DIsk의 작동 방식

작동방식에 대해서 전체적인 흐름을 알아보자.

> 전제 조건
> 
> 
> *CPU가 요청한 페이지가 1, 1, 1, 2, 2, 3, 2, 4 라고 가정한다. 
> 
> *메모리 영역은 3개의 페이지만을 보관할 수 있다.
> 
> *디스크에 1부터 4까지의 프로그램이 존재한다.
> 

CPU가 1번 페이지를 요청했으니 메모리에 1번이 올라오게 된다. (1번 프로세스 시작 및 가상메모리를 할당 받는 과정 생략) 이후 CPU는 1번을 추가적으로 요청하기 때문에 메모리와 디스크는 추가적인 작업을 진행할 필요가 없다. 

이후 2번을 요청해서 메모리에 2번이 올라가고 3번을 요청해서 3 메모리에 3번이 올라가고 다시 2번을 요청했기 때문에 메모리와 디스크는 별다른 작업을 진행하지 않을 것이다. 

마지막 요청으로 4번을 요청했는데 현재 메모리가 가득 찬 상태이다.이떼 메모리에 존재하는 페이지 중 어떤 페이지를 스왑영역으로 보낼 것인가에 대해서 생각해 보아야 한다. (페이지 교체 알고리즘)

## 페이지 교체 알고리즘

메모리가 꽉 차게 되면 메모리에 존재하는 페이지를 스왑 영역으로 보내야 한다. 이때, 어떤 페이지를 스왑영역으로 보낼것인가. (효율성을 중시하게 생각하면서 진행해야 한다.)

미래를 모르는 상황에서 미래에 다시 사용될 가능성이 높은 페이지를 쫒아내지 말고 가까운 미래에 사용되지 않을 페이지를 쫒아내는것이 메모리 관리의 핵심이다. 

(미래를 예측하는 가장 보통의 방법은 과거의 통계를 확인하고 미래를 예측하는 것이다.)

### LRU vs LFU

LRU : 가장 오래전에 참조한 페이지를 삭제한다는 알고리즘. (나의 예제로는 1번이 해당될 것이다.)

LFU : 참조횟수가 가장 적은 페이지를 삭제한다는 알고리즘.  (나의 예제로는 3번 또는 4번이 해당될 것이다.)

## 디스크 스케줄링

프로세스들의 요청이 시간 순서에 따라서 디스크 큐에 적재되면서 디스크에 저장되게 된다.

디스크에 접근해서 데이터를 저장하는데 가장 많은 소요 시간이 걸리는 부분이 디스크 헤드의 이동시간이다.

디스크 큐에 들어온 프로세스들의 요청이 1, 100, 3, 99 이런 식으로 중구난방일 경우 디스크 헤드가 1번 갔다 100번을 갔다가 계속 디스크 헤드를 옮겨야 하기 때문에 시간이 오래 걸리게 된다.

디스크를 효율적으로 관리하는 방법은 헤드의 이동을 최소한으로 줄여야 한다. 큐에 들어온 순서보다 들어온 순서를 뒤바꾸더라도 헤드의 이동 거리를 줄이는 방향으로 스케줄링해야 한다.

### 디스크 구성
![스크린샷 2023-06-05 오후 6 30 25](https://github.com/SionBackEnd/tech-sharing/assets/104377048/e525b121-f255-4344-94ac-771b7dbec19f)

**디스크 접근 시간(Access time)의 구성**

- 탐색시간(Seek time)
헤드를 해당 트랙(실린더)으로 움직이는데 걸리는 시간
- 회전지연(Rotational latency)
헤드가 원하는 섹터에 도달하기까지 걸리는 시간
- 전송시간(Transfer time)
실제 데이터의 전송 시간

**디스크 스케줄링(DIsk Scheduling)**

- Seek time을 최소화하는 것이 목표이다.
- Seek time은 Seek distance의 비레한다.

### FCFS (First-Come First-Served)

먼저 들어온대로 해결해 주는 알고리즘으로 디스크 스케줄링에서는 사용하지 않는 알고리즘이다. 
![스크린샷 2023-06-05 오후 6 44 15](https://github.com/SionBackEnd/tech-sharing/assets/104377048/3791fc68-0a56-4bcc-9ec3-f580f8257de7)



### SSTF (Shortest Seek Time First)

현재 위치한 트랙 기준으로 큐에 존재하는 요청 트랙 중 Seek time이 가장 짧은 곳을 먼저 처리해 주는 알고리즘이다.

하지만 이 방법도 사용을 하지 않는다. 

- 이동시간이 확실히 짧아지지만, 큰 문제점이 하나 존재한다. Starvation 문제점이 존재한다.
- Queue에 계속해서 요청이 들어오기 때문에 Seek time이 가장 긴 트랙은 작업을 진행하지 못하게 된다.
    
   ![스크린샷 2023-06-05 오후 6 44 48](https://github.com/SionBackEnd/tech-sharing/assets/104377048/6f4eb23b-8310-4c59-96ea-bf210b5a91c2)

    

### SCAN

헤드가 디스크의 한쪽 끝에서 다른 쪽 끝으로 이동하며 가는 길목에 있는 모든 요청을 처리한다.

다른 한쪽 끝에 도달하면 역방향으로 이동하며 오는 길목에 있는 모든 요청을 처리하며 다시 반대쪽 끝으로 이동한다.

- 큐의 요청을 전혀 생각하지 않고 지그재그로 가는길목에 작업이 존재하면 작업을 진행하고 지나가게 되는 알고리즘이다.
- 특정 위치라고 작업을 진행하지 못하게 되는 기아현상도 없고 헤드의 이동거리도 짧아지게 만든다.
- 엘레베이터 스켈줄링과 비슷하다.

![스크린샷 2023-06-05 오후 6 45 24](https://github.com/SionBackEnd/tech-sharing/assets/104377048/689545d4-3b67-4874-bea5-46d742d7cecd)


## 빠른 CPU와 느린 I/O의 속도차이를 완충하는 방법

저장장치의 계층 구조는 아래와 같다. 

**Primary (CPU가 직접 접근이 가능한 공간이다)**

- Registers
- Cache Memory
- Main Memory

---

**Secondary (CPU가 직접 사용불가. CPU가 사용 시 Primary에 적제해서 사용해야 한다.)**

- Magnetic Disk
- Optical Disk
- Magnetic Tape

> 요즘은 Disk 위에 Flash Memory를 사용하고 있다. 이전에는 Magnetic Tape에서 백업을 해두었는데 요즘은 Disk를 백업으로 사용하는 추세이다.
> 
- **속도**
위에서부터 아래로 내려올수록 속도가 느려진다.
- **가격**
위에서부터 아래로 내려올수록 가격이 낮아진다.
- **휘발성**
Primary 영역에 존재하는 것은 휘발성이고, Secondary 영역에 존재하는 것은 비휘발성이다.

계층 구조를 하는 이유 → 속도차이를 완충하기 위함이다.

모든 데이터가 저장되는 공간이 맨 하단이기 때문에 Register부터 아래로 내려가면서 저장을 하게 되고, 데이터를 사용하기 위해서는 Magnetic Tape에서부터 올라가면서 Register까지 올라가게 된다. 

### Caching

한번 사용한 데이터를 다시 사용할 때는 빠른 계층에 저장을 해두고 그 복사본을 전달함으로써 맨 하단까지 내려가지 않게 만드는 것 (**더 빠른 저장 시스템에 데이터를 복사해 두는 행위**)

## 플래시메모리

- 반도체 장치이다.
- NAND형(스토리지), NOR형(임베디드 코드 저장용) 보통 사람들이 사용하는 것은 모두 NAND형이다.

**특징**

- 비휘발성 메모리이다.
- 하드디스크에 비해 전력소모가 적다.
- 하드디스크에 비해 물리적인 충격에 더 적다.
- 크기가 작고 가볍다.
- 쓰기 횟수 제약(예시로 한 플래시메모리의 쓰기 횟수가 10만 번이라면 10만 번 이후에는 쓰기 작업을 진행할 수 없다.)
- 플래시메모리의 전하량이 일정시간 지나면 변질이 되므로 데이터가 시간이 흐르면서 변질될 수 있다. (하드디스크는 변질이 없다.)

**플래시메모리의 사용 형태**

- 휴대폰이나 임베디드 시스템 구성용
- USB용 메모리 스틱
- 모바일 장치 뿐 아니라 대용량 시스템에서 SSD(Solid State Drive)란 이름으로 하드디스크를 대체하기 시작했다.
